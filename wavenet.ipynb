{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['.'] + sorted(list(set(''.join(words))))\n",
    "encode = lambda c: chars.index(c)\n",
    "decode = lambda i: chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 3\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for c in w + '.':\n",
    "            ix = encode(c)\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xval, Yval = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... -----> y\n",
      "..y -----> u\n",
      ".yu -----> h\n",
      "yuh -----> e\n",
      "uhe -----> n\n",
      "hen -----> g\n",
      "eng -----> .\n",
      "... -----> d\n",
      "..d -----> i\n",
      ".di -----> o\n",
      "dio -----> n\n",
      "ion -----> d\n",
      "ond -----> r\n",
      "ndr -----> e\n",
      "dre -----> .\n",
      "... -----> x\n",
      "..x -----> a\n",
      ".xa -----> v\n",
      "xav -----> i\n",
      "avi -----> e\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "    print(''.join(decode(x_i.item()) for x_i in x), '----->', decode(y.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, embedding_num, embedding_dim) -> None:\n",
    "        self.embeddings = torch.randn((embedding_num, embedding_dim))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = self.embeddings[x]\n",
    "        return self.out.view(x.shape[0], -1)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.embeddings]\n",
    "    \n",
    "class Flatten:\n",
    "    def __call__(self, x):\n",
    "        self.out = x.view(x.shape[0], -1)\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out), generator=g) / (fan_in)**0.5\n",
    "        self.bias = torch.zeros((fan_out)) if bias else None\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "\n",
    "class BatchNorm1d:\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters for batch norm\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers trained with a running momentum update\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            xmean = x.mean(dim=0, keepdim=True)\n",
    "            xvar = x.var(dim=0, keepdim=True)\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        \n",
    "        self.out = (x - xmean) / (xvar + self.eps).sqrt()\n",
    "        self.out = self.out * self.gamma + self.beta\n",
    "\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = self.running_mean * (1 - self.momentum) + xmean * self.momentum\n",
    "                self.running_var = self.running_var * (1 - self.momentum) + xvar * self.momentum\n",
    "        \n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "class Sequential:\n",
    "    def __init__(self, layers) -> None:\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "def initialize_model(n_layers = 6, tanh = True, bn = False, bnOutput = False, output_scale = 0.1, hidden_gain = 5/3):\n",
    "    layers = [Embedding(vocab_size, n_embd), Flatten()]\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            layers.append(Linear(n_embd * block_size, n_hidden, bias=not bn))\n",
    "        elif i == n_layers - 1:\n",
    "            layers.append(Linear(n_hidden, vocab_size, bias=not bnOutput))\n",
    "        else:\n",
    "            layers.append(Linear(n_hidden, n_hidden, bias=not bn))\n",
    "\n",
    "        if bn and i < n_layers - 1:\n",
    "            layers.append(BatchNorm1d(n_hidden))\n",
    "        if tanh and i < n_layers - 1:\n",
    "            layers.append(Tanh())\n",
    "\n",
    "    if bnOutput:\n",
    "        layers.append(BatchNorm1d(vocab_size))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # last layer: make less confident\n",
    "        if bnOutput:\n",
    "            layers[-1].gamma *= output_scale\n",
    "        else:\n",
    "            layers[-1].weight *= output_scale\n",
    "        # all other layers: apply gain\n",
    "        for layer in layers[:-1]:\n",
    "            if isinstance(layer, Linear):\n",
    "                layer.weight *= hidden_gain\n",
    "\n",
    "    model = Sequential(layers)\n",
    "    parameters = model.parameters()\n",
    "    print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "    for p in parameters:\n",
    "        p.requires_grad = True\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model(n_layers=2, bn=True, hidden_gain=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, breakpoint = math.inf, lr=0.1):\n",
    "  # same optimization as last time\n",
    "  max_steps = 200000\n",
    "  batch_size = 32\n",
    "  lossi = []\n",
    "\n",
    "  for i in range(max_steps):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "    \n",
    "    logits = model(Xb)\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "    \n",
    "    # backward pass\n",
    "    for p in model.parameters():\n",
    "      p.grad = None\n",
    "      \n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    learning_rate = lr if i < 150000 else lr/10 # step learning rate decay\n",
    "    for p in model.parameters():\n",
    "      p.data += -learning_rate * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "    if breakpoint == i:\n",
    "      break\n",
    "  return lossi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 2.2499\n",
      "  10000/ 200000: 2.0491\n",
      "  20000/ 200000: 2.3003\n",
      "  30000/ 200000: 2.0917\n",
      "  40000/ 200000: 1.9374\n",
      "  50000/ 200000: 1.9730\n",
      "  60000/ 200000: 2.1145\n",
      "  70000/ 200000: 2.1131\n",
      "  80000/ 200000: 2.2099\n",
      "  90000/ 200000: 2.1483\n",
      " 100000/ 200000: 2.0874\n",
      " 110000/ 200000: 2.3142\n",
      " 120000/ 200000: 2.3746\n",
      " 130000/ 200000: 1.9890\n",
      " 140000/ 200000: 2.4010\n"
     ]
    }
   ],
   "source": [
    "lossi = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a913eb1510>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1,1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_training(model):\n",
    "  for layer in model.layers:\n",
    "    layer.training = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train nan\n",
      "val nan\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(model,split):\n",
    "  disable_training(model)\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xval, Yval),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss(model,'train')\n",
    "split_loss(model,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "probability tensor contains either `inf`, `nan` or element < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[144], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# sample from the distribution\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# shift the context window and track the samples\u001b[39;00m\n\u001b[0;32m     10\u001b[0m context \u001b[38;5;241m=\u001b[39m context[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m [ix]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: probability tensor contains either `inf`, `nan` or element < 0"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    disable_training(model)\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      logits = model(torch.tensor([context]))\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      # sample from the distribution\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      # shift the context window and track the samples\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      # if we sample the special '.' token, break\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(decode(i) for i in out)) # decode and print the generated word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
